{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c433478",
   "metadata": {},
   "source": [
    "this set up was made with the help of this guide https://nbviewer.org/github/microsoft/AIforEarthDataSets/blob/main/data/sentinel-5p.ipynb#Auth-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2eee72",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1854d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fsspec\n",
    "import json\n",
    "import urllib3\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from azure.storage.blob import ContainerClient\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Not used directly, but needs to be installed to read NetCDF files with xarray\n",
    "import h5netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981776a",
   "metadata": {},
   "source": [
    "# get Product & Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95b5df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter date [yyyy/mm/dd]: 2022/03/01\n",
      "enter your choice of Gas (O3 / NO2 / CH4): CH4\n"
     ]
    }
   ],
   "source": [
    "input_date = input('enter date [yyyy/mm/dd]: ')\n",
    "input_gas = input('enter your choice of Gas (O3 / NO2 / CH4): ')\n",
    "\n",
    "if input_gas == 'CH4':\n",
    "    product = 'L2__CH4___'\n",
    "else:\n",
    "    if input_gas == 'NO2':\n",
    "        product = 'L2__NO2___'\n",
    "    else:\n",
    "        product = 'L2__O3____'\n",
    "        \n",
    "date = input_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3213dc",
   "metadata": {},
   "source": [
    "# get Token from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a54c390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_Token_Data():\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('GET', 'https://planetarycomputer.microsoft.com/api/sas/v1/token/sentinel5euwest/sentinel-5p')\n",
    "    data = json.loads(response.data.decode('utf-8'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe463978",
   "metadata": {},
   "source": [
    "# Check Token File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213b39f",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449cc9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_empty(file_path):\n",
    "    # check if file exist and is empty\n",
    "    return os.path.exists(file_path) and os.stat(file_path).st_size == 0\n",
    "\n",
    "def getTime():\n",
    "    dt = datetime().now().astimezone(timezone.pst)\n",
    "    dt_string = dt.isoformat(timespec = 'milliseconds').replace('+00:00', 'Z')\n",
    "    return dt_string\n",
    "    \n",
    "def checkToken(jsonData):\n",
    "    token_expiration = jsonData['msft:expiry']\n",
    "    currTime = getTime()\n",
    "    if token_expiration <= currTime :\n",
    "        print('token expired! expiration Time: ', currTime)\n",
    "        return 0\n",
    "    else:\n",
    "        print('token still Valid! expiration Time ', curTime)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729205e0",
   "metadata": {},
   "source": [
    "## Read Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c354d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_path = './tokens/sentinel-5p_sas.json'\n",
    "is_empty = is_file_empty(sas_path)\n",
    "\n",
    "if is_empty != 0:\n",
    "    with open(sas_path, 'r+') as f:\n",
    "        data = json.load(f)\n",
    "        if checkToken(data):\n",
    "            sas_token=data['token']\n",
    "        else:\n",
    "            newData = get_Token_Data()\n",
    "            sas_token = newData['token']\n",
    "            f.seek(0)\n",
    "            json.dump(newData, f)\n",
    "else:\n",
    "    with open(sas_path, 'r+') as f:\n",
    "        newData = get_Token_Data()\n",
    "        sas_token = newData['token']\n",
    "        f.seek(0)\n",
    "        json.dump(newData, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda9ea7a",
   "metadata": {},
   "source": [
    "# Azure storage constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab8afb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_name = 'sentinel5euwest'\n",
    "container_name = 'sentinel-5p'\n",
    "storage_account_url = 'https://' + storage_account_name + '.blob.core.windows.net/'\n",
    "\n",
    "container_client = ContainerClient(account_url=storage_account_url, \n",
    "                                                container_name=container_name,\n",
    "                                                credential=sas_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342124d1",
   "metadata": {},
   "source": [
    "# List products matching our product/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe9a8498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for prefix TROPOMI/L2__CH4___/2022/03/01\n",
      "\n",
      "Found 14 matching scenes:\n",
      "\n",
      "S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456.nc\n",
      "S5P_OFFL_L2__CH4____20220301T022635_20220301T040805_22696_02_020301_20220302T181137.nc\n",
      "S5P_OFFL_L2__CH4____20220301T040805_20220301T054936_22697_02_020301_20220302T200810.nc\n",
      "S5P_OFFL_L2__CH4____20220301T054936_20220301T073106_22698_02_020301_20220302T220046.nc\n",
      "S5P_OFFL_L2__CH4____20220301T073106_20220301T091237_22699_02_020301_20220302T234452.nc\n",
      "S5P_OFFL_L2__CH4____20220301T091237_20220301T105407_22700_02_020301_20220303T012017.nc\n",
      "S5P_OFFL_L2__CH4____20220301T105407_20220301T123537_22701_02_020301_20220303T031500.nc\n",
      "S5P_OFFL_L2__CH4____20220301T123537_20220301T141708_22702_02_020301_20220303T044722.nc\n",
      "S5P_OFFL_L2__CH4____20220301T141708_20220301T155838_22703_02_020301_20220303T061839.nc\n",
      "S5P_OFFL_L2__CH4____20220301T155838_20220301T174008_22704_02_020301_20220303T075219.nc\n",
      "S5P_OFFL_L2__CH4____20220301T174008_20220301T192139_22705_02_020301_20220303T100224.nc\n",
      "S5P_OFFL_L2__CH4____20220301T192139_20220301T210309_22706_02_020301_20220303T113041.nc\n",
      "S5P_OFFL_L2__CH4____20220301T210309_20220301T224440_22707_02_020301_20220303T125033.nc\n",
      "S5P_OFFL_L2__CH4____20220301T224440_20220302T002610_22708_02_020301_20220303T143253.nc\n"
     ]
    }
   ],
   "source": [
    "prefix = '/'.join(['TROPOMI',product,date])\n",
    "print('Searching for prefix {}'.format(prefix))\n",
    "generator = container_client.list_blobs(name_starts_with=prefix)\n",
    "scene_paths = [blob.name for blob in generator]\n",
    "print('\\nFound {} matching scenes:\\n'.format(len(scene_paths)))\n",
    "for s in scene_paths:\n",
    "    print(s.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e254b",
   "metadata": {},
   "source": [
    "# Print Metadata for one scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0594f3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image at URL:\n",
      "https://sentinel5euwest.blob.core.windows.net/sentinel-5p/TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T123537_20220301T141708_22702_02_020301_20220303T044722/S5P_OFFL_L2__CH4____20220301T123537_20220301T141708_22702_02_020301_20220303T044722.nc\n"
     ]
    }
   ],
   "source": [
    "#different gas use different sc_mode, default CH4\n",
    "sc_mode = 'OFFL'\n",
    "if (product == 'L2__NO2___'):\n",
    "    sc_mode = 'NRTI'\n",
    "#need to add sc_mode for the other gases. will probably move this part to the beginning\n",
    "\n",
    "offl_scenes = [s for s in scene_paths if sc_mode in s]\n",
    "scene_path = offl_scenes[len(offl_scenes) // 2]\n",
    "url = storage_account_url + container_name + '/' + scene_path\n",
    "print('Processing image at URL:\\n{}'.format(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9132c",
   "metadata": {},
   "source": [
    "## Sign URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa45453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://sentinel5euwest.blob.core.windows.net/sentinel-5p/TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T123537_20220301T141708_22702_02_020301_20220303T044722/S5P_OFFL_L2__CH4____20220301T123537_20220301T141708_22702_02_020301_20220303T044722.nc?st=2022-04-10T18%3A09%3A51Z&se=2022-04-11T18%3A54%3A51Z&sp=rl&sv=2020-06-12&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2022-04-10T22%3A04%3A03Z&ske=2022-04-17T22%3A04%3A03Z&sks=b&skv=2020-06-12&sig=5J5e9eyI8vDkF6RjFnrQ3sf%2BnKnvBKVThF9h6Fqdezs%3D\n"
     ]
    }
   ],
   "source": [
    "import planetary_computer\n",
    "import pystac\n",
    "import rasterio\n",
    "\n",
    "#item: pystac.Item = ... # no idea what goes here been trying multiple things but still stuck\n",
    "b4_href = planetary_computer.sign(url) #i think this sign the url directly\n",
    "\n",
    "print(b4_href)\n",
    "#this print a url if clicked would download the scene\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee26430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_dirs(dest_path):\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path)\n",
    "    elif not os.path.isdir(dest_path):\n",
    "        shutil.rmtree(dst_path)\n",
    "        os.makedirs(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea406ee6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456/S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456.nc to data\\TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456/S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456.nc\n",
      "Downloading TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T022635_20220301T040805_22696_02_020301_20220302T181137/S5P_OFFL_L2__CH4____20220301T022635_20220301T040805_22696_02_020301_20220302T181137.nc to data\\TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T022635_20220301T040805_22696_02_020301_20220302T181137/S5P_OFFL_L2__CH4____20220301T022635_20220301T040805_22696_02_020301_20220302T181137.nc\n",
      "Downloading TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T040805_20220301T054936_22697_02_020301_20220302T200810/S5P_OFFL_L2__CH4____20220301T040805_20220301T054936_22697_02_020301_20220302T200810.nc to data\\TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T040805_20220301T054936_22697_02_020301_20220302T200810/S5P_OFFL_L2__CH4____20220301T040805_20220301T054936_22697_02_020301_20220302T200810.nc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m _create_dirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fname))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m download_file:\n\u001b[1;32m---> 11\u001b[0m     download_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mblob_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreadall())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:83\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\azure\\storage\\blob\\_blob_client.py:848\u001b[0m, in \u001b[0;36mBlobClient.download_blob\u001b[1;34m(self, offset, length, **kwargs)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"Downloads a blob to the StorageStreamDownloader. The readall() method must\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;124;03mbe used to read all the content or readinto() must be used to download the blob into\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;124;03ma stream. Using chunks() returns an iterator which allows the user to iterate over the content in chunks.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m        :caption: Download a blob.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    844\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_blob_options(\n\u001b[0;32m    845\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m    846\u001b[0m     length\u001b[38;5;241m=\u001b[39mlength,\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StorageStreamDownloader(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\azure\\storage\\blob\\_download.py:349\u001b[0m, in \u001b[0;36mStorageStreamDownloader.__init__\u001b[1;34m(self, clients, config, start_range, end_range, validate_content, encryption_options, max_concurrency, name, container, encoding, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m     initial_request_end \u001b[38;5;241m=\u001b[39m initial_request_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_get_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_range, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_offset \u001b[38;5;241m=\u001b[39m process_range_and_offset(\n\u001b[0;32m    346\u001b[0m     initial_request_start, initial_request_end, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_end_range, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encryption_options\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response\u001b[38;5;241m.\u001b[39mproperties\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\azure\\storage\\blob\\_download.py:435\u001b[0m, in \u001b[0;36mStorageStreamDownloader._initial_request\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_content \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encryption_options\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     retry_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mChunkedEncodingError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError) \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\azure\\storage\\blob\\_download.py:52\u001b[0m, in \u001b[0;36mprocess_content\u001b[1;34m(data, start_offset, end_offset, encryption)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse cannot be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content \u001b[38;5;129;01mand\u001b[39;00m encryption\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m encryption\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolver\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\azure\\core\\pipeline\\transport\\_requests_basic.py:148\u001b[0m, in \u001b[0;36mStreamDownloadGenerator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m    150\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\requests\\models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 760\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    761\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\urllib3\\response.py:576\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[1;32m--> 576\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    579\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\site-packages\\urllib3\\response.py:519\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 519\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    521\u001b[0m         amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[0;32m    522\u001b[0m     ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\http\\client.py:462\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    461\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 462\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\http\\client.py:506\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    501\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    503\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 506\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SeniorProject\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We cannot access and read the files directly from the blob. We will need to download it first.\n",
    "blob_list = container_client.list_blobs(name_starts_with=prefix)\n",
    "for blob in blob_list:\n",
    "        fname = os.path.join('data', blob.name)\n",
    "        print(f'Downloading {blob.name} to {fname}')\n",
    "\n",
    "        # get blob client which has download_blob method\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        _create_dirs(os.path.dirname(fname))\n",
    "        with open(fname, \"wb\") as download_file:\n",
    "            download_file.write(blob_client.download_blob().readall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4707d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'data\\TROPOMI/L2__CH4___/2022/03/01/S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456/S5P_OFFL_L2__CH4____20220301T004505_20220301T022635_22695_02_020301_20220302T164456.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0fc4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Group'>\n",
      "group /PRODUCT:\n",
      "    dimensions(sizes): scanline(4172), ground_pixel(215), corner(4), time(1), layer(12), level(13)\n",
      "    variables(dimensions): int32 scanline(scanline), int32 ground_pixel(ground_pixel), int32 time(time), int32 corner(corner), int32 layer(layer), int32 level(level), int32 delta_time(time, scanline), <class 'str'> time_utc(time, scanline), uint8 qa_value(time, scanline, ground_pixel), float32 latitude(time, scanline, ground_pixel), float32 longitude(time, scanline, ground_pixel), float32 methane_mixing_ratio(time, scanline, ground_pixel), float32 methane_mixing_ratio_precision(time, scanline, ground_pixel), float32 methane_mixing_ratio_bias_corrected(time, scanline, ground_pixel)\n",
      "    groups: SUPPORT_DATA\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "fh = Dataset(data, mode = 'r')\n",
    "\n",
    "print(fh.groups['PRODUCT'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
